---
layout: page
title: Link Prediction with GNNs and Text Features
description: Using text features generated from passing review texts into a Language Model, to predict the links between reviewers using Graph Neural Networks (GNNs)
img: assets/img/colab_coverimg.png
importance: 2
category: coding
related_publications: false
---

## Motivations
I was reading about Graph Neural Networks (GNNs), and I came across Cora, a citation network dataset of scientific publications, which included Bag-of-Words(BoW) word embeddings as node features for training GNNs on the Cora dataset.

In 2021, I worked on a similar dataset on metal music reviews, where I defined two users (i.e. reviewers) to be connected if they have reviewed a common album
(See <a href="https://link.springer.com/article/10.1007/s13278-022-00863-2">Here</a>). I was interested to find out whether this metal music review dataset could similarly be used to train GNNs.

## Methodology

<a href="https://github.com/jzh001/GNNs/tree/main/metal_music_reviews">Github Repository</a>

I wondered if a GNN would be useful in predicting whether two users were likely to review a same album (and hence be related), when using text embeddings extracted from all review texts generated by each reviewer (hence forming a profile of each reviewer). I experimented training 2 GNNs, seperately using both BoW embeddings based on word frequencies, and paragraph embeddings based on the hidden states of a language model.

For the language model, I used a <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">MiniLM model</a>, because of its smaller number of parameters, and the fact that it was trained on social media data, which works well for reviews. For each reviewer (i.e. user), I concatenated all of the review texts generated by that specific user. Thereafter, I ran the language model on all the user reviews, and for each user, I extracted the hidden states after the forward pass to use as a "summary" text embedding vector for each user, representing each user's "profile". I froze the language model(LM) parameters to not backpropagate through the entire LM to save computation.

The GNN model I used was a simple one, comprising of graph convolutions, graph attention, layer normalizations and negative sampling. Using the same initial GNN model, I separately trained the model on both BoW and MiniLM text embeddings.

## Findings

Both the BoW and MiniLM embeddings obtained similar accuracy of around 83% for link prediction. This is compared to the baseline of 50% for random guessing, as I sampled the same number of negative edges as the number of positive edges.

I suspected that this accuracy was more likely due to the structure of the graph than the text embeddings itself, as accuracy seems to be preserved even when I lower the dimension of the word embeddings extracted. However, the text features do contribute to greater stability in training, as it is observed that higher dimensional word embeddings leads to smaller divergence between the positive and negative link prediction accuracies. In other words, there was smaller fluctuations in accuracy, and the likelihood that an interaction was correctly predicted to be true was close to the likelihood that an interaction was correctly predicted to be false.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/GNN_losses.png" title="Loss Graph" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/GNN_accs.png" title="Accuracy Graph" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Left: Loss vs Epochs, Right: Accuracy vs Epochs
</div>


<a href="https://github.com/jzh001/GNNs/tree/main/metal_music_reviews">Github Repository</a>

<a href="https://github.com/jzh001/GNNs/tree/main">Check out my other related GNN projects</a>

